{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = './datasets/'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_data = CIFAR100(root=path,train=True,transform=transform,download=True)\n",
    "test_data = CIFAR100(root=path,train=False,transform=transform,download=True)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_data,batch_size=batch_size,shuffle=False,num_workers=0)\n",
    "\n",
    "input_shape = train_data[0][0].shape\n",
    "output_shape = len(train_data.classes)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00],\n",
       "        [ 5.4030e-01,  8.4147e-01,  9.8747e-01,  1.5783e-01,  9.9968e-01,\n",
       "          2.5116e-02,  9.9999e-01,  3.9811e-03,  1.0000e+00,  6.3096e-04],\n",
       "        [-4.1615e-01,  9.0930e-01,  9.5018e-01,  3.1170e-01,  9.9874e-01,\n",
       "          5.0217e-02,  9.9997e-01,  7.9621e-03,  1.0000e+00,  1.2619e-03],\n",
       "        [-9.8999e-01,  1.4112e-01,  8.8908e-01,  4.5775e-01,  9.9716e-01,\n",
       "          7.5285e-02,  9.9993e-01,  1.1943e-02,  1.0000e+00,  1.8929e-03],\n",
       "        [-6.5364e-01, -7.5680e-01,  8.0569e-01,  5.9234e-01,  9.9496e-01,\n",
       "          1.0031e-01,  9.9987e-01,  1.5924e-02,  1.0000e+00,  2.5238e-03]])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 10\n",
    "max_len = 5\n",
    "\n",
    "pos_enc = torch.zeros(max_len,d_model,requires_grad=False)\n",
    "pos = torch.arange(0, max_len, 1, requires_grad=False).reshape(-1,1) \n",
    "w_vector = 10000**(-2*(torch.arange(0, (d_model // 2), 1))/d_model)\n",
    "\n",
    "pos_enc[:,0::2] = torch.cos(pos * w_vector)\n",
    "pos_enc[:,1::2] = torch.sin(pos * w_vector)\n",
    "\n",
    "pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pos * w_vector / w_vector).size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PositionalEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "# refer to Section 3.5 in the paper\n",
    "\n",
    "    def __init__(self, device, max_len=512, d_model=16):\n",
    "        super().__init__()\n",
    "        self.pos_enc = torch.zeros(max_len,d_model,requires_grad=False, device=device)\n",
    "        pos = torch.arange(0, max_len, 1, requires_grad=False, device=device).reshape(-1,1) \n",
    "        w_vector = 10000**(-2*(torch.arange(0, (d_model // 2), 1, device=device))/d_model)\n",
    "\n",
    "        self.pos_enc[:,0::2] = torch.cos(pos * w_vector)\n",
    "        self.pos_enc[:,1::2] = torch.sin(pos * w_vector)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x.shape = [batch_size, seq_len, data_dim]\n",
    "        \"\"\"\n",
    "        return x + self.pos_enc[:x.shape[1], :].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScaledDotProductAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self,d_model=16):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # fill out here\n",
    "        # compute attention value based on transformed query, key, value where mask is given conditionally\n",
    "        \"\"\"\n",
    "        q, k, v = transformed query, key, value\n",
    "        q.shape, k.shape, v.shpae = [batch_size, num_head, seq_len, d_ff=d_model/num_head]\n",
    "        mask = masking matrix, if the index has value False, kill the value; else, leave the value\n",
    "        \"\"\"\n",
    "        k_T = k.transpose(-1,-2)\n",
    "\n",
    "        # 1. matmul Q @ K_T\n",
    "        scores = (q @ k_T) / torch.sqrt(torch.tensor(q.shape[-1]))\n",
    "\n",
    "        # ( Optional ) masking \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(~mask, float('-inf'))\n",
    "\n",
    "        # 2. softmax\n",
    "        attention_weight = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # 3. matmul attention_weight @ V\n",
    "        attention_value = attention_weight @ v\n",
    "\n",
    "        return attention_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_model=16,num_head=4):\n",
    "        super().__init__()\n",
    "        assert d_model % num_head == 0, \"check if d_model is divisible by num_head\"\n",
    "\n",
    "        # params\n",
    "        self.d_model = d_model\n",
    "        self.num_head = num_head\n",
    "        self.d_ff = d_model//num_head\n",
    "\n",
    "        # q, k, v's weight \n",
    "        self.q_weight = nn.Linear(d_model, d_model)\n",
    "        self.k_weight = nn.Linear(d_model, d_model)  \n",
    "        self.v_weight = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # output weight for concat \n",
    "        self.output_weight =  nn.Linear(d_model, d_model)  \n",
    "\n",
    "        # set attention block \n",
    "        self.attention = ScaledDotProductAttention(d_model=d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # fill out here\n",
    "        # compute multi-head attention value\n",
    "        # here, query, key, value are pre-transformed, so you need to transfrom them in this module\n",
    "        \"\"\"\n",
    "        q, k, v = pre-transformed query, key, value\n",
    "        q.shape, k.shape, v.shpae = [batch_size, seq_len, d_model]\n",
    "        mask = masking matrix, if the index has value False, kill the value; else, leave the value\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, d_model = q.shape\n",
    "\n",
    "        # make them learnable \n",
    "        q, k, v = self.q_weight(q), self.k_weight(k), self.v_weight(v)\n",
    "\n",
    "        # reshape [batch_size, seq_len, d_model] to [batch_size, num_head, seq_len, d_ff]\n",
    "        def reshape(x):\n",
    "            return x.view(batch_size, seq_len, self.num_head, self.d_ff).transpose(1,2)\n",
    "        \n",
    "        q, k, v = reshape(q), reshape(k), reshape(v)\n",
    "\n",
    "        # calculate attention value \n",
    "        attention_value = self.attention(q,k,v,mask=mask)\n",
    "        \n",
    "        # concat heads --> result :  [batch_size, seq_len, d_model]\n",
    "        concated_value = attention_value.transpose(1,2).reshape(batch_size, seq_len, d_model)\n",
    "\n",
    "        output = self.output_weight(concated_value)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PositionwiseFeedForwardNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForwardNetwork(nn.Module):\n",
    "    def __init__(self,d_model=16,d_ff=32):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Masking(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x.shape = (batch_size, seq_len, data_dim)\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        mask = torch.tril(torch.ones(seq_len, seq_len, dtype=torch.bool, device=self.device))\n",
    "        mask = mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LayerNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [논문](https://arxiv.org/pdf/1607.06450) 읽어서 보충하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://paperswithcode.com/method/layer-normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self,d_model=16,eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(-1, keepdim=True) \n",
    "        var = x.var(-1, unbiased=False, keepdim=True) \n",
    "\n",
    "        normed = (x - mean)/torch.sqrt(var + self.eps) # 정규화\n",
    "        normed = self.gamma * normed + self.beta # 파라미터 추가 \n",
    "\n",
    "        return normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,d_model=16,num_head=4,d_ff=32,drop_prob=.1):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, num_head)\n",
    "        self.norm1 = LayerNormalization(d_model)\n",
    "\n",
    "        self.ffn = PositionwiseFeedForwardNetwork(d_model, d_ff)\n",
    "        self.norm2 = LayerNormalization(d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self,enc):\n",
    "        # multi head attention\n",
    "        _x = enc\n",
    "        x = self.attention(q=enc, k=enc, v=enc)\n",
    "\n",
    "        # add and norm\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm1(x + _x)\n",
    "\n",
    "        # feed forward\n",
    "        _x = x\n",
    "        x = self.ffn(x)\n",
    "\n",
    "        # add and norm\n",
    "        x = self.dropout(x)\n",
    "        output = self.norm2(x + _x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,d_model=16,num_head=4,d_ff=32,drop_prob=.1):\n",
    "        super().__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model, num_head)\n",
    "        self.norm1 = LayerNormalization(d_model)\n",
    "\n",
    "        self.enc_dec_attention = MultiHeadAttention(d_model, num_head)\n",
    "        self.norm2 = LayerNormalization(d_model)\n",
    "\n",
    "        self.ffn = PositionwiseFeedForwardNetwork(d_model, d_ff)\n",
    "        self.norm3 = LayerNormalization(d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self,enc_output,dec,dec_mask):\n",
    "        # multi head attention\n",
    "        _x = dec\n",
    "        x = self.self_attention(q=dec, k=dec, v=dec, mask=dec_mask)\n",
    "\n",
    "        # add and norm\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm1(x + _x)\n",
    "\n",
    "        # enc - dec attention\n",
    "        if enc_output is not None:\n",
    "            _x = x\n",
    "            x = self.enc_dec_attention(q=x, k=enc_output, v=enc_output)\n",
    "\n",
    "            # add and norm\n",
    "            x = self.dropout(x)\n",
    "            x = self.norm2(x + _x)\n",
    "\n",
    "        # feed forward\n",
    "        _x = x\n",
    "        x = self.ffn(x)\n",
    "\n",
    "        # add and norm\n",
    "        x = self.dropout(x)\n",
    "        output = self.norm3(x + _x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "# refer to Section 3.1 and Figure 1 in the paper\n",
    "# this is a whole encoder, i.e., the left side of Figure 1, consists of the following as well\n",
    "# input embedding, positional encoding\n",
    "    \"\"\"\n",
    "    in this homework, encoder inputs are not tokens, it is already embeddings in the input dimension\n",
    "    hence, you don't have to set input embedding layer\n",
    "    instead, you have to transform the input into the hidden dimension with single linear transformation\n",
    "    \"\"\"\n",
    "    def __init__(self,device,input_dim=3,num_layer=3,max_len=512,d_model=16,num_head=4,d_ff=32,drop_prob=.1):\n",
    "        super().__init__()\n",
    "        self.positional_emb = PositionalEncoding(device=device,\n",
    "                                                 max_len=max_len,\n",
    "                                                 d_model=d_model)\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model=d_model,\n",
    "                                                  num_head=num_head,\n",
    "                                                  d_ff=d_ff,\n",
    "                                                  drop_prob=drop_prob)\n",
    "                                                  for _ in range(num_layer)])\n",
    "        \n",
    "        self.input_fc = nn.Linear(input_dim, d_model)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # transform dimension : embedding이 없어서 필요한 부분\n",
    "        x = self.input_fc(x)\n",
    "\n",
    "        x = self.positional_emb(x) \n",
    "\n",
    "        for layer in self.layers:\n",
    "            hidden = layer(x)\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "# refer to Section 3.1 and Figure 1 in the paper\n",
    "# this is a whole decoder, i.e., the left side of Figure 1, consists of the following as well\n",
    "# input embedding, positional encoding, linear classifier\n",
    "    \"\"\"\n",
    "    in this homework, decoder inputs are not tokens, it is already embeddings in the input dimension\n",
    "    hence, you don't have to set input embedding layer\n",
    "    instead, you have to transform the input into the hidden dimension with single linear transformation\n",
    "    \"\"\"\n",
    "    def __init__(self,device,input_dim=3,num_layer=3,max_len=512,d_model=16,num_head=4,d_ff=32,drop_prob=.1):\n",
    "        super().__init__()\n",
    "        self.positional_emb = PositionalEncoding(device=device,\n",
    "                                                 max_len=max_len,\n",
    "                                                 d_model=d_model)\n",
    "\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model=d_model,\n",
    "                                                  num_head=num_head,\n",
    "                                                  d_ff=d_ff,\n",
    "                                                  drop_prob=drop_prob)\n",
    "                                     for _ in range(num_layer)])\n",
    "        \n",
    "        self.input_fc = nn.Linear(input_dim, d_model)\n",
    "        self.output_fc = nn.Linear(d_model, input_dim)\n",
    "\n",
    "    def forward(self,enc_output,y,y_mask):\n",
    "\n",
    "        y = self.input_fc(y)           # (B, 1024, d_model)\n",
    "        y = self.positional_emb(y)\n",
    "\n",
    "        # y_mask shape should be (B, seq_len, seq_len) or (1, seq_len, seq_len)\n",
    "        for layer in self.layers:\n",
    "            y = layer(enc_output=enc_output, dec=y, dec_mask=y_mask)\n",
    "\n",
    "        output = self.output_fc(y)          # (B, 1024, 3)\n",
    "        # output = y.view(batch_size, c, h, h)  # (B, 3, 32, 32)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self,device,input_dim=3,num_layer=3,max_len=512,d_model=16,num_head=4,d_ff=32,drop_prob=.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(device=device,\n",
    "                               input_dim=input_dim,\n",
    "                               num_layer=num_layer,\n",
    "                               max_len=max_len,\n",
    "                               d_model=d_model,\n",
    "                               num_head=num_head,\n",
    "                               d_ff=d_ff,\n",
    "                               drop_prob=drop_prob)\n",
    "\n",
    "        self.decoder = Decoder(device=device,\n",
    "                               input_dim=input_dim,\n",
    "                               num_layer=num_layer,\n",
    "                               max_len=max_len,\n",
    "                               d_model=d_model,\n",
    "                               num_head=num_head,\n",
    "                               d_ff=d_ff,\n",
    "                               drop_prob=drop_prob)\n",
    "\n",
    "        self.masking = Masking(device=device)\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        # mask\n",
    "        mask = self.masking(y)\n",
    "\n",
    "        # encoder\n",
    "        enc_output = self.encoder(x)\n",
    "\n",
    "        # decoder\n",
    "        dec_output = self.decoder(enc_output,y,mask)\n",
    "\n",
    "        # softmax\n",
    "        # dec_output = F.softmax(dec_output, dim=-1)\n",
    "        # loss = nn.BCEWithLogitsLoss(reduction='sum')가 이거라서 주석 처리 \n",
    "        return dec_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScheduledOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScheduledOptimizer:\n",
    "    def __init__(self,optimizer,d_model=16,warmup_steps=4000):\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.step_num = 0\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def update_parameter_and_learning_rate(self):\n",
    "        self.optimizer.step()\n",
    "        self.step_num += 1\n",
    "        self.lr = self.d_model**(-.5) * min(self.step_num**(-.5),self.step_num*self.warmup_steps**(-1.5))\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = self.lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Transformer(device=device,input_dim=3,num_layer=3,max_len=512,d_model=16,num_head=4,d_ff=64,drop_prob=.1).to(device)\n",
    "loss = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters(),betas=(.9,.98),eps=1e-9)\n",
    "scheduled_optimizer = ScheduledOptimizer(optimizer,d_model=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 100\n",
    "train_loss_list, test_loss_list = list(), list()\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"num_param:\", total_params)\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    \n",
    "    ## train\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "\n",
    "        image = image.reshape(-1,3,1024).transpose(1,2)\n",
    "        x, y = image[:,:512,:].to(device), image[:,512:,:].to(device)\n",
    "\n",
    "        y_ = torch.zeros([batch_size,1,3],requires_grad=False).to(device)\n",
    "        y_ = torch.cat([y_,y[:,:-1,:]],dim=1)\n",
    "        \n",
    "        logit = model.forward(x,y_)\n",
    "        cost = loss(logit, y)/(3*512)\n",
    "        \n",
    "        total_loss += cost.item()\n",
    "\n",
    "        scheduled_optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        scheduled_optimizer.update_parameter_and_learning_rate()\n",
    "        \n",
    "    ave_loss = total_loss/len(train_data)\n",
    "    train_loss_list.append(ave_loss)\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        print(\"\\nEpoch %d Train: %.3f w/ Learning Rate: %.5f\"%(i,ave_loss,scheduled_optimizer.lr))\n",
    "\n",
    "    ## test\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (image, label) in enumerate(test_loader):\n",
    "\n",
    "            image = image.reshape(-1,3,1024).transpose(1,2)\n",
    "            x, y = image[:,:512,:].to(device), image[:,512:,:].to(device)\n",
    "\n",
    "            y_ = torch.zeros([batch_size,1,3],requires_grad=False).to(device)\n",
    "            y_ = torch.cat([y_,y[:,:-1,:]],dim=1)\n",
    "            \n",
    "            logit = model.forward(x,y_)\n",
    "            cost = loss(logit, y)/(3*512)\n",
    "\n",
    "            total_loss += cost.item()\n",
    "\n",
    "    ave_loss = total_loss/len(test_data)\n",
    "    test_loss_list.append(ave_loss)\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        print(\"Epoch %d Test: %.3f\"%(i,ave_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_param: 23219\n",
    "\n",
    "Epoch 0 Train: 0.618 w/ Learning Rate: 0.00049\n",
    "Epoch 0 Test: 0.567\n",
    "\n",
    "Epoch 1 Train: 0.562 w/ Learning Rate: 0.00099\n",
    "Epoch 1 Test: 0.556\n",
    "\n",
    "Epoch 2 Train: 0.557 w/ Learning Rate: 0.00148\n",
    "Epoch 2 Test: 0.554\n",
    "\n",
    "Epoch 3 Train: 0.555 w/ Learning Rate: 0.00198\n",
    "Epoch 3 Test: 0.553\n",
    "\n",
    "Epoch 4 Train: 0.555 w/ Learning Rate: 0.00247\n",
    "Epoch 4 Test: 0.552\n",
    "\n",
    "Epoch 5 Train: 0.553 w/ Learning Rate: 0.00296\n",
    "Epoch 5 Test: 0.550\n",
    "\n",
    "Epoch 6 Train: 0.548 w/ Learning Rate: 0.00346\n",
    "Epoch 6 Test: 0.543\n",
    "\n",
    "Epoch 7 Train: 0.544 w/ Learning Rate: 0.00395\n",
    "Epoch 7 Test: 0.542\n",
    "\n",
    "Epoch 8 Train: 0.543 w/ Learning Rate: 0.00373\n",
    "Epoch 8 Test: 0.541\n",
    "\n",
    "Epoch 9 Train: 0.543 w/ Learning Rate: 0.00354\n",
    "Epoch 9 Test: 0.540\n",
    "\n",
    "Epoch 10 Train: 0.542 w/ Learning Rate: 0.00337\n",
    "Epoch 10 Test: 0.540\n",
    "\n",
    "Epoch 11 Train: 0.542 w/ Learning Rate: 0.00323\n",
    "Epoch 11 Test: 0.540\n",
    "\n",
    "Epoch 12 Train: 0.541 w/ Learning Rate: 0.00310\n",
    "Epoch 12 Test: 0.539\n",
    "\n",
    "Epoch 13 Train: 0.540 w/ Learning Rate: 0.00299\n",
    "Epoch 13 Test: 0.539\n",
    "\n",
    "Epoch 14 Train: 0.540 w/ Learning Rate: 0.00289\n",
    "Epoch 14 Test: 0.538\n",
    "\n",
    "Epoch 15 Train: 0.540 w/ Learning Rate: 0.00280\n",
    "Epoch 15 Test: 0.538\n",
    "\n",
    "Epoch 16 Train: 0.539 w/ Learning Rate: 0.00271\n",
    "Epoch 16 Test: 0.538\n",
    "\n",
    "Epoch 17 Train: 0.539 w/ Learning Rate: 0.00264\n",
    "Epoch 17 Test: 0.538\n",
    "\n",
    "Epoch 18 Train: 0.539 w/ Learning Rate: 0.00256\n",
    "Epoch 18 Test: 0.537\n",
    "\n",
    "Epoch 19 Train: 0.539 w/ Learning Rate: 0.00250\n",
    "Epoch 19 Test: 0.537\n",
    "\n",
    "Epoch 20 Train: 0.539 w/ Learning Rate: 0.00244\n",
    "Epoch 20 Test: 0.537\n",
    "\n",
    "Epoch 21 Train: 0.539 w/ Learning Rate: 0.00238\n",
    "Epoch 21 Test: 0.537\n",
    "\n",
    "Epoch 22 Train: 0.539 w/ Learning Rate: 0.00233\n",
    "Epoch 22 Test: 0.537\n",
    "\n",
    "Epoch 23 Train: 0.538 w/ Learning Rate: 0.00228\n",
    "Epoch 23 Test: 0.537\n",
    "\n",
    "Epoch 24 Train: 0.538 w/ Learning Rate: 0.00224\n",
    "Epoch 24 Test: 0.537\n",
    "\n",
    "Epoch 25 Train: 0.538 w/ Learning Rate: 0.00219\n",
    "Epoch 25 Test: 0.536\n",
    "\n",
    "Epoch 26 Train: 0.538 w/ Learning Rate: 0.00215\n",
    "Epoch 26 Test: 0.537\n",
    "\n",
    "Epoch 27 Train: 0.538 w/ Learning Rate: 0.00211\n",
    "Epoch 27 Test: 0.536\n",
    "\n",
    "Epoch 28 Train: 0.538 w/ Learning Rate: 0.00208\n",
    "Epoch 28 Test: 0.536\n",
    "\n",
    "Epoch 29 Train: 0.538 w/ Learning Rate: 0.00204\n",
    "Epoch 29 Test: 0.537\n",
    "\n",
    "Epoch 30 Train: 0.538 w/ Learning Rate: 0.00201\n",
    "Epoch 30 Test: 0.536\n",
    "\n",
    "Epoch 31 Train: 0.538 w/ Learning Rate: 0.00198\n",
    "Epoch 31 Test: 0.536\n",
    "\n",
    "Epoch 32 Train: 0.538 w/ Learning Rate: 0.00195\n",
    "Epoch 32 Test: 0.536\n",
    "\n",
    "Epoch 33 Train: 0.538 w/ Learning Rate: 0.00192\n",
    "Epoch 33 Test: 0.536\n",
    "\n",
    "Epoch 34 Train: 0.538 w/ Learning Rate: 0.00189\n",
    "Epoch 34 Test: 0.536\n",
    "\n",
    "Epoch 35 Train: 0.538 w/ Learning Rate: 0.00186\n",
    "Epoch 35 Test: 0.536\n",
    "\n",
    "Epoch 36 Train: 0.538 w/ Learning Rate: 0.00184\n",
    "Epoch 36 Test: 0.536\n",
    "\n",
    "Epoch 37 Train: 0.538 w/ Learning Rate: 0.00181\n",
    "Epoch 37 Test: 0.536\n",
    "\n",
    "Epoch 38 Train: 0.538 w/ Learning Rate: 0.00179\n",
    "Epoch 38 Test: 0.536\n",
    "\n",
    "Epoch 39 Train: 0.538 w/ Learning Rate: 0.00177\n",
    "Epoch 39 Test: 0.536\n",
    "\n",
    "Epoch 40 Train: 0.538 w/ Learning Rate: 0.00175\n",
    "Epoch 40 Test: 0.536\n",
    "\n",
    "Epoch 41 Train: 0.538 w/ Learning Rate: 0.00173\n",
    "Epoch 41 Test: 0.536\n",
    "\n",
    "Epoch 42 Train: 0.538 w/ Learning Rate: 0.00170\n",
    "Epoch 42 Test: 0.536\n",
    "\n",
    "Epoch 43 Train: 0.537 w/ Learning Rate: 0.00169\n",
    "Epoch 43 Test: 0.536\n",
    "\n",
    "Epoch 44 Train: 0.537 w/ Learning Rate: 0.00167\n",
    "Epoch 44 Test: 0.536\n",
    "\n",
    "Epoch 45 Train: 0.537 w/ Learning Rate: 0.00165\n",
    "Epoch 45 Test: 0.536\n",
    "\n",
    "Epoch 46 Train: 0.537 w/ Learning Rate: 0.00163\n",
    "Epoch 46 Test: 0.536\n",
    "\n",
    "Epoch 47 Train: 0.537 w/ Learning Rate: 0.00161\n",
    "Epoch 47 Test: 0.536\n",
    "\n",
    "Epoch 48 Train: 0.537 w/ Learning Rate: 0.00160\n",
    "Epoch 48 Test: 0.536\n",
    "\n",
    "Epoch 49 Train: 0.537 w/ Learning Rate: 0.00158\n",
    "Epoch 49 Test: 0.536\n",
    "\n",
    "Epoch 50 Train: 0.537 w/ Learning Rate: 0.00157\n",
    "Epoch 50 Test: 0.536\n",
    "\n",
    "Epoch 51 Train: 0.537 w/ Learning Rate: 0.00155\n",
    "Epoch 51 Test: 0.536\n",
    "\n",
    "Epoch 52 Train: 0.537 w/ Learning Rate: 0.00154\n",
    "Epoch 52 Test: 0.536\n",
    "\n",
    "Epoch 53 Train: 0.537 w/ Learning Rate: 0.00152\n",
    "Epoch 53 Test: 0.536\n",
    "\n",
    "Epoch 54 Train: 0.537 w/ Learning Rate: 0.00151\n",
    "Epoch 54 Test: 0.536\n",
    "\n",
    "Epoch 55 Train: 0.537 w/ Learning Rate: 0.00149\n",
    "Epoch 55 Test: 0.536\n",
    "\n",
    "Epoch 56 Train: 0.537 w/ Learning Rate: 0.00148\n",
    "Epoch 56 Test: 0.536\n",
    "\n",
    "Epoch 57 Train: 0.537 w/ Learning Rate: 0.00147\n",
    "Epoch 57 Test: 0.536\n",
    "\n",
    "Epoch 58 Train: 0.537 w/ Learning Rate: 0.00146\n",
    "Epoch 58 Test: 0.536\n",
    "\n",
    "Epoch 59 Train: 0.537 w/ Learning Rate: 0.00144\n",
    "Epoch 59 Test: 0.536\n",
    "\n",
    "Epoch 60 Train: 0.537 w/ Learning Rate: 0.00143\n",
    "Epoch 60 Test: 0.536\n",
    "\n",
    "Epoch 61 Train: 0.537 w/ Learning Rate: 0.00142\n",
    "Epoch 61 Test: 0.536\n",
    "\n",
    "Epoch 62 Train: 0.537 w/ Learning Rate: 0.00141\n",
    "Epoch 62 Test: 0.536\n",
    "\n",
    "Epoch 63 Train: 0.537 w/ Learning Rate: 0.00140\n",
    "Epoch 63 Test: 0.536\n",
    "\n",
    "Epoch 64 Train: 0.537 w/ Learning Rate: 0.00139\n",
    "Epoch 64 Test: 0.536\n",
    "\n",
    "Epoch 65 Train: 0.537 w/ Learning Rate: 0.00138\n",
    "Epoch 65 Test: 0.536\n",
    "\n",
    "Epoch 66 Train: 0.537 w/ Learning Rate: 0.00137\n",
    "Epoch 66 Test: 0.536\n",
    "\n",
    "Epoch 67 Train: 0.537 w/ Learning Rate: 0.00136\n",
    "Epoch 67 Test: 0.536\n",
    "\n",
    "Epoch 68 Train: 0.537 w/ Learning Rate: 0.00135\n",
    "Epoch 68 Test: 0.536\n",
    "\n",
    "Epoch 69 Train: 0.537 w/ Learning Rate: 0.00134\n",
    "Epoch 69 Test: 0.536\n",
    "\n",
    "Epoch 70 Train: 0.537 w/ Learning Rate: 0.00133\n",
    "Epoch 70 Test: 0.536\n",
    "\n",
    "Epoch 71 Train: 0.537 w/ Learning Rate: 0.00132\n",
    "Epoch 71 Test: 0.536\n",
    "\n",
    "Epoch 72 Train: 0.537 w/ Learning Rate: 0.00131\n",
    "Epoch 72 Test: 0.536\n",
    "\n",
    "Epoch 73 Train: 0.537 w/ Learning Rate: 0.00130\n",
    "Epoch 73 Test: 0.536\n",
    "\n",
    "Epoch 74 Train: 0.537 w/ Learning Rate: 0.00129\n",
    "Epoch 74 Test: 0.536\n",
    "\n",
    "Epoch 75 Train: 0.537 w/ Learning Rate: 0.00128\n",
    "Epoch 75 Test: 0.536\n",
    "\n",
    "Epoch 76 Train: 0.537 w/ Learning Rate: 0.00127\n",
    "Epoch 76 Test: 0.536\n",
    "\n",
    "Epoch 77 Train: 0.537 w/ Learning Rate: 0.00127\n",
    "Epoch 77 Test: 0.536\n",
    "\n",
    "Epoch 78 Train: 0.537 w/ Learning Rate: 0.00126\n",
    "Epoch 78 Test: 0.536\n",
    "\n",
    "Epoch 79 Train: 0.537 w/ Learning Rate: 0.00125\n",
    "Epoch 79 Test: 0.536\n",
    "\n",
    "Epoch 80 Train: 0.537 w/ Learning Rate: 0.00124\n",
    "Epoch 80 Test: 0.536\n",
    "\n",
    "Epoch 81 Train: 0.537 w/ Learning Rate: 0.00123\n",
    "Epoch 81 Test: 0.536\n",
    "\n",
    "Epoch 82 Train: 0.537 w/ Learning Rate: 0.00123\n",
    "Epoch 82 Test: 0.536\n",
    "\n",
    "Epoch 83 Train: 0.537 w/ Learning Rate: 0.00122\n",
    "Epoch 83 Test: 0.536\n",
    "\n",
    "Epoch 84 Train: 0.537 w/ Learning Rate: 0.00121\n",
    "Epoch 84 Test: 0.536\n",
    "\n",
    "Epoch 85 Train: 0.537 w/ Learning Rate: 0.00121\n",
    "Epoch 85 Test: 0.536\n",
    "\n",
    "Epoch 86 Train: 0.537 w/ Learning Rate: 0.00120\n",
    "Epoch 86 Test: 0.536\n",
    "\n",
    "Epoch 87 Train: 0.537 w/ Learning Rate: 0.00119\n",
    "Epoch 87 Test: 0.536\n",
    "\n",
    "Epoch 88 Train: 0.537 w/ Learning Rate: 0.00119\n",
    "Epoch 88 Test: 0.536\n",
    "\n",
    "Epoch 89 Train: 0.537 w/ Learning Rate: 0.00118\n",
    "Epoch 89 Test: 0.536\n",
    "\n",
    "Epoch 90 Train: 0.537 w/ Learning Rate: 0.00117\n",
    "Epoch 90 Test: 0.536\n",
    "\n",
    "Epoch 91 Train: 0.537 w/ Learning Rate: 0.00117\n",
    "Epoch 91 Test: 0.536\n",
    "\n",
    "Epoch 92 Train: 0.537 w/ Learning Rate: 0.00116\n",
    "Epoch 92 Test: 0.536\n",
    "\n",
    "Epoch 93 Train: 0.537 w/ Learning Rate: 0.00115\n",
    "Epoch 93 Test: 0.536\n",
    "\n",
    "Epoch 94 Train: 0.537 w/ Learning Rate: 0.00115\n",
    "Epoch 94 Test: 0.536\n",
    "\n",
    "Epoch 95 Train: 0.537 w/ Learning Rate: 0.00114\n",
    "Epoch 95 Test: 0.536\n",
    "\n",
    "Epoch 96 Train: 0.537 w/ Learning Rate: 0.00114\n",
    "Epoch 96 Test: 0.536\n",
    "\n",
    "Epoch 97 Train: 0.537 w/ Learning Rate: 0.00113\n",
    "Epoch 97 Test: 0.536\n",
    "\n",
    "Epoch 98 Train: 0.537 w/ Learning Rate: 0.00112\n",
    "Epoch 98 Test: 0.536\n",
    "\n",
    "Epoch 99 Train: 0.537 w/ Learning Rate: 0.00112\n",
    "Epoch 99 Test: 0.536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_prediction(x, y_true, y_pred, idx=0):\n",
    "    \"\"\"\n",
    "    시각화를 위한 함수\n",
    "    x       : 입력 이미지 시퀀스 (B, 512, 3)\n",
    "    y_true  : 실제 타겟 이미지 시퀀스 (B, 512, 3)\n",
    "    y_pred  : 모델 출력 (B, 512, 3)\n",
    "    idx     : 시각화할 배치 내 인덱스\n",
    "    \"\"\"\n",
    "    # concat input and predicted\n",
    "    input_half = x[idx]             # (512, 3)\n",
    "    gt_half    = y_true[idx]        # (512, 3)\n",
    "    pred_half  = y_pred[idx].detach().cpu()  # (512, 3)\n",
    "\n",
    "    input_img = input_half.view(16, 32, 3).permute(2, 0, 1)   # (C, H, W)\n",
    "    gt_img    = gt_half.view(16, 32, 3).permute(2, 0, 1)\n",
    "    pred_img  = pred_half.view(16, 32, 3).permute(2, 0, 1)\n",
    "\n",
    "    # 합쳐서 전체 이미지\n",
    "    true_full = torch.cat([input_img, gt_img], dim=1)\n",
    "    pred_full = torch.cat([input_img, pred_img], dim=1)\n",
    "\n",
    "    # 시각화\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    axes[0].imshow(true_full.permute(1, 2, 0).clamp(0, 1).numpy())\n",
    "    axes[0].set_title(\"Ground Truth\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(pred_full.permute(1, 2, 0).clamp(0, 1).numpy())\n",
    "    axes[1].set_title(\"Prediction\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "        image = image.reshape(-1, 3, 1024).transpose(1, 2)\n",
    "        x, y = image[:, :512, :].to(device), image[:, 512:, :].to(device)\n",
    "\n",
    "        batch_size = image.size(0)\n",
    "        y_ = torch.zeros([batch_size, 1, 3], device=device)\n",
    "        y_ = torch.cat([y_, y[:, :-1, :]], dim=1)\n",
    "\n",
    "        pred = model(x, y_)\n",
    "\n",
    "        # 시각화: 첫 번째 배치만 확인하고 종료\n",
    "        visualize_prediction(x.cpu(), y.cpu(), pred.cpu(), idx=0)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AiGO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
